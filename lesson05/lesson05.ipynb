{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №5\n",
    "\n",
    "* Попробуйте изменить параметры нейронной сети работающей с датасетом imdb либо нейронной сети работающей airline-passengers(она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить ее точность. Приложите анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:28:49.364855Z",
     "start_time": "2020-04-27T07:25:00.255260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n",
      "Построение модели...\n",
      "Процесс обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xander/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.4581 - accuracy: 0.7824 - val_loss: 0.3614 - val_accuracy: 0.8410\n",
      "25000/25000 [==============================] - 39s 2ms/step\n",
      "Результат при тестировании: 0.3614186480045319\n",
      "Тестовая точность: 0.8410000205039978\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 80\n",
    "batch_size = 100 # увеличьте значение для ускорения обучения\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 200))\n",
    "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> для увеличения качества помогло увеличение количества юнитов\n",
    "\n",
    "#### Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:44:47.656922Z",
     "start_time": "2020-04-27T07:29:36.169020Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 38s 265us/step - loss: 2.4665\n",
      "Генерация из посева: t was all \n",
      "t was all and and and and and and and and and and and and and and and and and and and and and and and and and ==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 34s 240us/step - loss: 2.0122\n",
      "Генерация из посева:  a footman\n",
      " a footmang the made the made the made the made the made the made the made the made the made the made the made==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 34s 234us/step - loss: 1.8307\n",
      "Генерация из посева: yphon, `th\n",
      "yphon, `the master and the march and the march and the march and the march and the march and the march and the==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 40s 278us/step - loss: 1.7100\n",
      "Генерация из посева: der a tree\n",
      "der a tree the dors and the dory the doon the doon the doon the doon the doon the doon the doon the doon the d==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 37s 257us/step - loss: 1.6195\n",
      "Генерация из посева: yourself t\n",
      "yourself the door and the mouse the reater the mouse the reater the mouse the reater the mouse the reater the ==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 35s 247us/step - loss: 1.5485\n",
      "Генерация из посева: her head!'\n",
      "her head!' she said to the choored to see whe had not to the choored to see whe had not to the choored to see ==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 36s 251us/step - loss: 1.4890\n",
      "Генерация из посева:  day of th\n",
      " day of the reat of the hatter the mouse of the was the march hare the mock turtle and the more the caterpilla==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 35s 241us/step - loss: 1.4393\n",
      "Генерация из посева: was very g\n",
      "was very grow the cate piged the said to the parted the patter the mouse the pat and the pance the pat and the==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 35s 243us/step - loss: 1.3970\n",
      "Генерация из посева: th alice's\n",
      "th alice's said to herself `she was not in the was she had not a little to her head of the gryphon was so the ==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 36s 248us/step - loss: 1.3590\n",
      "Генерация из посева:  `come on!\n",
      " `come on!' `i can't the caterpillar in the caterpillar in the caterpillar in the caterpillar in the caterpill==================================================\n",
      "Итерация #: 10\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 45s 314us/step - loss: 1.3265\n",
      "Генерация из посева: heated her\n",
      "heated her hand of the same thing a moment the caterpillar in the caterpillar in the caterpillar in the caterp==================================================\n",
      "Итерация #: 11\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 36s 249us/step - loss: 1.2968\n",
      "Генерация из посева: ing.  `i'm\n",
      "ing.  `i'm grow up to see it made of the tried all the tries as she was not a mouse to be the read of the trie==================================================\n",
      "Итерация #: 12\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 35s 242us/step - loss: 1.2687\n",
      "Генерация из посева: had no ver\n",
      "had no very such a thing as a little gor that the words and things and she was a little gor that the words and==================================================\n",
      "Итерация #: 13\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 41s 284us/step - loss: 1.2443\n",
      "Генерация из посева: rough the \n",
      "rough the same thing as she said to herself, and the same thing as she said to herself, and the same thing as ==================================================\n",
      "Итерация #: 14\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 39s 270us/step - loss: 1.22230s - loss: 1\n",
      "Генерация из посева:  your litt\n",
      " your little shriek to get her feet on the whole party and looked at the poor little thing a very such a triee==================================================\n",
      "Итерация #: 15\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 37s 258us/step - loss: 1.2003\n",
      "Генерация из посева: oses growi\n",
      "oses growing and the gryphon and seemed to herself, `i won't wondering of the court, and then alice was going ==================================================\n",
      "Итерация #: 16\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 35s 244us/step - loss: 1.1801\n",
      "Генерация из посева:  back to t\n",
      " back to the court, and she said the king said to the court, and she said the king said to the court, and she ==================================================\n",
      "Итерация #: 17\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 31s 217us/step - loss: 1.1607\n",
      "Генерация из посева: xactly so,\n",
      "xactly so, and the same thing a tone of the song, and the same thing a tone of the song, and the same thing a ==================================================\n",
      "Итерация #: 18\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 36s 249us/step - loss: 1.1436\n",
      "Генерация из посева: ought, `an\n",
      "ought, `and they was so she was so she was so she was so she was so she was so she was so she was so she was s==================================================\n",
      "Итерация #: 19\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 37s 255us/step - loss: 1.1265\n",
      "Генерация из посева: d argued e\n",
      "d argued every now and the white rabbit have their shated on the sond, and she was not a minute or two she was==================================================\n",
      "Итерация #: 20\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 34s 238us/step - loss: 1.1107\n",
      "Генерация из посева: e dance? \"\n",
      "e dance? \"when the right and she was a little thing a triet in the sand and began to herself, `i won't you, wi==================================================\n",
      "Итерация #: 21\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 33s 233us/step - loss: 1.0947\n",
      "Генерация из посева: trial's be\n",
      "trial's began to repeat it as she spoke, and the rabbit was stopping them began to repeat it as she spoke, and==================================================\n",
      "Итерация #: 22\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 33s 233us/step - loss: 1.0795\n",
      "Генерация из посева: hen the pi\n",
      "hen the pigeon the panterpillar took the time then the reason of the time then the reason of the time then the==================================================\n",
      "Итерация #: 23\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 34s 236us/step - loss: 1.0662\n",
      "Генерация из посева: o--oop of \n",
      "o--oop of the court of the song, she had not at all the rest of the song, she had not at all the rest of the s==================================================\n",
      "Итерация #: 24\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 39s 269us/step - loss: 1.0525\n",
      "Генерация из посева: uchess sne\n",
      "uchess sneezed to be no court, as she said to herself, and the thing as she could not the time the table to he\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# построчное чтение из примера с текстом \n",
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "\n",
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 25 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "\n",
    "# Create a super simple recurrent neural network. There is one recurrent\n",
    "# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n",
    "# encoded input layer. This is followed by a Dense fully-connected layer\n",
    "# across the set of possible next characters, which is converted to a\n",
    "# probability score via a standard softmax activation with a multi-class\n",
    "# cross-entropy loss function linking the prediction to the one-hot\n",
    "# encoding character label.\n",
    "\n",
    "'''\n",
    "Создание очень простой рекуррентной нейронной сети. \n",
    "В ней будет один реккурентный закодированный входной слой. За ним последует полносвязный слой связанный с \n",
    "набором возможных следующих символов, которые конвертированы в вероятностные результаты через стандартную \n",
    "softmax активацию с multi-class cross-encoding loss функцию ссылающуются на предсказание one-hot \n",
    "encoding лейбл символа\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> думаю наиболее удачный текст который получился - вот такой:\n",
    "\n",
    ">> your little shriek to get her feet on the whole party and looked at the poor little thing a very such a triee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
